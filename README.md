# WebPuzac
A tool for webcrawling

*Info:*
The program is capable of looking at any url you give it and scraping all the links on that page and keeps scraping links on other pages it found.

*Last update:*
Fixed a milion bugs and made automode fully functional 

*Next update:*
Making the program look a bit nicer and making it capable of avoiding non existing websites

*Very important stuff:*
This program is open source so you can use it as a platform for further modification
Be careful with webcrawling on social networks because if you do that, you are putting yourself in a position where you can be sued by owners of the social networks for scraping their data.
More on that here: https://benbernardblog.com/web-scraping-and-crawling-are-perfectly-legal-right/


*Before running a program:*
The program requies a few packages, to do that open command prompt and type: 

pip install bs4

pip install urllib3

pip install requests


*How to run a program?*
The program is made to guide you trough using it, if something is not clear about what you have to do or how it works, type help anywhere and it will tell you what you want to know

*Switching between modes*
You can switch between auto and manual mode. 
When a program asks you if you want to proceed you have to tell it 'no' and it will ask if you want to switch to the other mode, if you say yes it will show you the same list again and ask you to proceed, and if you say no it will end the program. Stopping automode is impossible for now.


*Unexpected errors*
A program can suddenly halt and report an error, that is most likely due to the fact that some websites are locked and when you try to access those certain websites it will report an error, you can see more details on the error in the last line the program will output. 


Thats all for now folks, enjoy
